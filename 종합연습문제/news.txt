"미국의 인공지능(AI)연구소 오픈AI가 개발한 대화형AI ‘챗GPT(ChatGPT)’를 드론이나 로봇을 조종하는 데 활용하는 기술이 개발됐다. 그동안 챗GPT를 온라인상서 활용하는 것에서 나아가 물리적 행동을 조작하는 데도 쓰일 수 있게 됐다는 점에서 전문가들은 특히 주의가 필요하다고 지적한다.

6일 주요 외신에 따르면 마이크로소프트(MS)는 지난달 20일 로봇팔과 드론과 같은 다양한 로봇을 제어하는 소프트웨어 프로그래밍 과정에 챗GPT를 활용하는 방법에 대한 논문을 자사 홈페이지에 공개했다. 그동안 주로 논문 작성이나 시험, 질의응답 형식으로 활용되던 자연어 기반 챗GPT가 드론·로봇의 제어 프로그래밍에서도 활용될 수 있다는 것을 입증한 것이다.

사이 벰프라라 MS 자율시스템·로보틱스그룹 수석연구원 연구팀은 챗GPT를 로봇 시뮬레이터에 적용하는 방식으로 실험을 진행했다. 현재는 로봇을 제어하기 위해 엔지니어가 직접 코딩하는 방식을 사용하고 있지만, 이제는 챗GPT가 사용자의 요구에 맞춰 코드를 만들고 로봇을 제어하는 것이다.

연구팀은 자유 대화 형식을 사용해 챗GPT가 로봇을 제어할 수 있도록 로봇 API(운영체제와 응용프로그램 사이 통신에 사용되는 언어)를 학습시켰다. 또 로봇 제어 프로그래밍과 관련된 텍스트 프롬프트(명령어) 체계를 만들고, 프롬프트 체계를 공유할 수 있는 오픈 소스 플랫폼 ‘프롬프트크래프트(PromptCraft)’를 만들어 챗GPT의 로봇 제어 기술을 향상시킬 수 있도록 했다.

MS가 공개한 해당 논문 관련 영상을 살펴보면, ‘색깔 블록을 이용해 MS의 로고를 만들어달라’라는 명령어를 입력하자 챗GPT가 만든 코딩에 맞춰 로봇팔이 블록을 배열했다. 드론을 대상으로 한 ‘선반에 놓인 콜라 캔을 찾아달라’는 명령어에도 정확한 코딩을 도출해, 드론이 다른 물체가 아닌 콜라 캔만 카메라로 비췄다.

연구팀은 “이번 연구는 챗GPT가 텍스트를 넘어서 생각하고 로봇 작업을 돕기 위해 물리적 세계에 대해 추론할 수 있는지 확인하기 위한 것”이라며 “챗GPT가 스스로 많은 일을 할 수 있지만, 여전히 약간의 도움이 필요하다는 것이 밝혀졌다”라고 설명했다.
이번 MS의 연구 결과와 관련해 AI를 로봇 공학에 적용하는 게 시기상조라는 의견도 나온다. 생성 AI에서 흔히 보이는 ‘할루시네이션(hallucination·환각)’ 이슈나 인공지능 윤리를 정리하지 못한 상태에서 로봇에 대한 제어권을 넘기는 것은 위험하다는 주장이다.

마크 코켈버그 오스트리아 비엔나대 기술철학과 교수는 “컴퓨터의 제어권을 AI에게 넘기는 것은 매우 위험한 일이다”라며 “현대 AI의 문제는 사용자에게 투명하지 않다는 것이 가장 크다”고 말했다. 그러면서 코켈버그 교수는 AI가 물리적 기계를 제어하는 것을 생각하는 것조차 위험하다고 경고했다.

국내 전문가들도 코켈버그 교수와 비슷한 의견을 내놨다. 그동안 생성 AI의 문제점이 주로 온라인상에서 벌어졌다면, 로봇을 조종하는 것은 현실에서 물리력을 동반한 형태로 문제점을 노출할 수 있어 위험할 수 있다는 설명이다.

조성배 연세대 컴퓨터공학과 교수는 “챗GPT나 다른 AI의 기술을 완벽할 수 없기 때문에 원천적으로 위험 부담이 크다”라며 “이전에는 물리 세계와 단절돼 있었지만, 로봇이나 드론을 활용하는 것은 기존 AI 문제를 해결할 장치를 생각해야 한다”고 지적했다. 이어 “로봇에 활용한다면 법적으로나 윤리적으로나 대처할 방안을 마련해야 할 것”이라고 강조했다.

다만 거대모델 AI가 로봇 공학으로 발전하는 것은 자연스럽다는 의견도 있었다. 실제로 구글도 지난해 11월 AI가 스스로 로봇 제어 코드를 생성하고, 새로운 정보를 습득할 수 있는 모델을 제안한 바 있다.

김기응 한국과학기술원(KAIST) AI대학원 교수는 “챗GPT와 같은 거대모델을 개발하는 기업 입장에서는 AI 기술을 로보틱스 분야로 확장하는 것이 목적”이라며 “이미 다양한 기업에서 시도 중이고, 기존 대형 언어 모델의 문제점과 비슷한 수준이라고 본다”고 말했다."
